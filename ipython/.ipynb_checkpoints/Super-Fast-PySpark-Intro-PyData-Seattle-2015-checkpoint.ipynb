{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\apps\\dist\\spark-1.3.1.2.2.6.1-0012\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print os.environ['SPARK_HOME']\n",
    "src = \"file:///\"+os.environ['SPARK_HOME']+\"/README.md\"\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "sc = SparkContext( 'spark://headnodehost:7077', 'pyspark')\n",
    "\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'', 75),\n",
       " (u'all', 1),\n",
       " (u'when', 1),\n",
       " (u'\"local\"', 1),\n",
       " (u'including', 3),\n",
       " (u'computation', 1),\n",
       " (u'Spark](#building-spark).', 1),\n",
       " (u'using:', 1),\n",
       " (u'guidance', 3),\n",
       " (u'Scala,', 1),\n",
       " (u'environment', 1),\n",
       " (u'only', 1),\n",
       " (u'rich', 1),\n",
       " (u'Apache', 1),\n",
       " (u'sc.parallelize(range(1000)).count()', 1),\n",
       " (u'Building', 1),\n",
       " (u'guide,', 1),\n",
       " (u'return', 2),\n",
       " (u'Please', 3),\n",
       " (u'Try', 1),\n",
       " (u'not', 1),\n",
       " (u'Spark', 14),\n",
       " (u'scala>', 1),\n",
       " (u'Note', 1),\n",
       " (u'cluster.', 1),\n",
       " (u'./bin/pyspark', 1),\n",
       " (u'have', 1),\n",
       " (u'params', 1),\n",
       " (u'through', 1),\n",
       " (u'GraphX', 1),\n",
       " (u'[run', 1),\n",
       " (u'abbreviated', 1),\n",
       " (u'[project', 2),\n",
       " (u'##', 8),\n",
       " (u'library', 1),\n",
       " (u'see', 1),\n",
       " (u'[Apache', 1),\n",
       " (u'will', 1),\n",
       " (u'#', 1),\n",
       " (u'processing,', 2),\n",
       " (u'for', 11),\n",
       " (u'[building', 1),\n",
       " (u'provides', 1),\n",
       " (u'print', 1),\n",
       " (u'supports', 2),\n",
       " (u'built,', 1),\n",
       " (u'[params]`.', 1),\n",
       " (u'available', 1),\n",
       " (u'run', 7),\n",
       " (u'This', 2),\n",
       " (u'Hadoop,', 2),\n",
       " (u'Tests', 1),\n",
       " (u'example:', 1),\n",
       " (u'-DskipTests', 1),\n",
       " (u'Maven](http://maven.apache.org/).', 1),\n",
       " (u'programming', 1),\n",
       " (u'running', 1),\n",
       " (u'against', 1),\n",
       " (u'site,', 1),\n",
       " (u'comes', 1),\n",
       " (u'package.', 1),\n",
       " (u'and', 10),\n",
       " (u'package.)', 1),\n",
       " (u'prefer', 1),\n",
       " (u'documentation,', 1),\n",
       " (u'submit', 1),\n",
       " (u'tools', 1),\n",
       " (u'use', 3),\n",
       " (u'from', 1),\n",
       " (u'For', 2),\n",
       " (u'fast', 1),\n",
       " (u'systems.', 1),\n",
       " (u'Version\"](http://spark.apache.org/docs/latest/building-with-maven.html#specifying-the-hadoop-version)',\n",
       "  1),\n",
       " (u'<http://spark.apache.org/>', 1),\n",
       " (u'Hadoop-supported', 1),\n",
       " (u'way', 1),\n",
       " (u'README', 1),\n",
       " (u'MASTER', 1),\n",
       " (u'engine', 1),\n",
       " (u'building', 3),\n",
       " (u'usage', 1),\n",
       " (u'Distributions\"](http://spark.apache.org/docs/latest/hadoop-third-party-distributions.html)',\n",
       "  1),\n",
       " (u'instance:', 1),\n",
       " (u'with', 4),\n",
       " (u'protocols', 1),\n",
       " (u'And', 1),\n",
       " (u'this', 1),\n",
       " (u'setup', 1),\n",
       " (u'shell:', 2),\n",
       " (u'project', 1),\n",
       " (u'See', 1),\n",
       " (u'following', 2),\n",
       " (u'distribution', 1),\n",
       " (u'detailed', 2),\n",
       " (u'file', 1),\n",
       " (u'stream', 1),\n",
       " (u'is', 6),\n",
       " (u'higher-level', 1),\n",
       " (u'tests', 1),\n",
       " (u'1000:', 2),\n",
       " (u'sample', 1),\n",
       " (u'[\"Specifying', 1),\n",
       " (u'Alternatively,', 1),\n",
       " (u'./bin/run-example', 2),\n",
       " (u'need', 1),\n",
       " (u'You', 3),\n",
       " (u'instructions.', 1),\n",
       " (u'different', 1),\n",
       " (u'programs,', 1),\n",
       " (u'storage', 1),\n",
       " (u'same', 1),\n",
       " (u'machine', 1),\n",
       " (u'Running', 1),\n",
       " (u'which', 2),\n",
       " (u'you', 4),\n",
       " (u'A', 1),\n",
       " (u'About', 1),\n",
       " (u'sc.parallelize(1', 1),\n",
       " (u'locally.', 1),\n",
       " (u'Hive', 2),\n",
       " (u'optimized', 1),\n",
       " (u'uses', 1),\n",
       " (u'variable', 1),\n",
       " (u'The', 1),\n",
       " (u'data', 2),\n",
       " (u'a', 9),\n",
       " (u'Thriftserver', 1),\n",
       " (u'processing.', 1),\n",
       " (u'./bin/spark-shell', 1),\n",
       " (u'Python', 2),\n",
       " (u'mvn', 1),\n",
       " (u'clean', 1),\n",
       " (u'the', 21),\n",
       " (u'requires', 1),\n",
       " (u'talk', 1),\n",
       " (u'help', 1),\n",
       " (u'automated', 1),\n",
       " (u'Hadoop', 4),\n",
       " (u'using', 2),\n",
       " (u'high-level', 1),\n",
       " (u'find', 1),\n",
       " (u'web', 1),\n",
       " (u'Shell', 2),\n",
       " (u'how', 2),\n",
       " (u'graph', 1),\n",
       " (u'run:', 1),\n",
       " (u'should', 2),\n",
       " (u'to', 14),\n",
       " (u'given.', 1),\n",
       " (u'directory.', 1),\n",
       " (u'must', 1),\n",
       " (u'do', 2),\n",
       " (u'Programs', 1),\n",
       " (u'Many', 1),\n",
       " (u'\"yarn-client\"', 1),\n",
       " (u'YARN,', 1),\n",
       " (u'[\"Third', 1),\n",
       " (u'Example', 1),\n",
       " (u'Once', 1),\n",
       " (u'Spark\"](http://spark.apache.org/docs/latest/building-spark.html).', 1),\n",
       " (u'Because', 1),\n",
       " (u'name', 1),\n",
       " (u'Testing', 1),\n",
       " (u'refer', 2),\n",
       " (u'Streaming', 1),\n",
       " (u'SQL', 2),\n",
       " (u'them,', 1),\n",
       " (u'analysis.', 1),\n",
       " (u'application', 1),\n",
       " (u'set', 2),\n",
       " (u'Scala', 2),\n",
       " (u'thread,', 1),\n",
       " (u'examples', 2),\n",
       " (u'runs.', 1),\n",
       " (u'Pi', 1),\n",
       " (u'More', 1),\n",
       " (u'Python,', 2),\n",
       " (u'Versions', 1),\n",
       " (u'its', 1),\n",
       " (u'version', 1),\n",
       " (u'wiki](https://cwiki.apache.org/confluence/display/SPARK).', 1),\n",
       " (u'`./bin/run-example', 1),\n",
       " (u'Configuration', 1),\n",
       " (u'command,', 2),\n",
       " (u'<class>', 1),\n",
       " (u'core', 1),\n",
       " (u'MASTER=spark://host:7077', 1),\n",
       " (u'Documentation', 1),\n",
       " (u'downloaded', 1),\n",
       " (u'distributions.', 1),\n",
       " (u'Spark.', 1),\n",
       " (u'[\"Building', 1),\n",
       " (u'`examples`', 2),\n",
       " (u'on', 6),\n",
       " (u'works', 1),\n",
       " (u'package', 1),\n",
       " (u'of', 5),\n",
       " (u'changed', 1),\n",
       " (u'pre-built', 1),\n",
       " (u'Big', 1),\n",
       " (u'\"yarn-cluster\"', 1),\n",
       " (u'or', 3),\n",
       " (u'learning,', 1),\n",
       " (u'structured', 1),\n",
       " (u'overview', 1),\n",
       " (u'one', 2),\n",
       " (u'tests](https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark#ContributingtoSpark-AutomatedTesting).',\n",
       "  1),\n",
       " (u'(You', 1),\n",
       " (u'Online', 1),\n",
       " (u'versions', 1),\n",
       " (u'your', 1),\n",
       " (u'threads.', 1),\n",
       " (u'APIs', 1),\n",
       " (u'SparkPi', 2),\n",
       " (u'contains', 1),\n",
       " (u'system', 1),\n",
       " (u'class', 2),\n",
       " (u'start', 1),\n",
       " (u'basic', 1),\n",
       " (u'configure', 1),\n",
       " (u'that', 3),\n",
       " (u'N', 1),\n",
       " (u'guide](http://spark.apache.org/docs/latest/configuration.html)', 1),\n",
       " (u'>>>', 1),\n",
       " (u'particular', 3),\n",
       " (u'be', 2),\n",
       " (u'an', 3),\n",
       " (u'easiest', 1),\n",
       " (u'Interactive', 2),\n",
       " (u'cluster', 2),\n",
       " (u'programs', 2),\n",
       " (u'can', 6),\n",
       " (u'locally', 2),\n",
       " (u'example', 3),\n",
       " (u'are', 1),\n",
       " (u'Data.', 1),\n",
       " (u'mesos://', 1),\n",
       " (u'computing', 1),\n",
       " (u'URL,', 1),\n",
       " (u'in', 5),\n",
       " (u'general', 2),\n",
       " (u'To', 2),\n",
       " (u'at', 2),\n",
       " (u'1000).count()', 1),\n",
       " (u'Party', 1),\n",
       " (u'if', 4),\n",
       " (u'built', 1),\n",
       " (u'no', 1),\n",
       " (u'Java,', 1),\n",
       " (u'\"local[N]\"', 1),\n",
       " (u'MLlib', 1),\n",
       " (u'also', 5),\n",
       " (u'other', 1),\n",
       " (u'build', 3),\n",
       " (u'online', 1),\n",
       " (u'several', 1),\n",
       " (u'distribution.', 1),\n",
       " (u'HDFS', 1),\n",
       " (u'[Configuration', 1),\n",
       " (u'spark://', 1),\n",
       " (u'page](http://spark.apache.org/documentation.html)', 1),\n",
       " (u'documentation', 3),\n",
       " (u'It', 2),\n",
       " (u'graphs', 1),\n",
       " (u'./dev/run-tests', 1),\n",
       " (u'first', 1),\n",
       " (u'latest', 1)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = sc.textFile(src)\n",
    "words = lines.flatMap(lambda x: x.split(\" \"))\n",
    "word_count = (\n",
    "  words.map(lambda x: (x, 1))\n",
    "            .reduceByKey(lambda x, y: x+y))\n",
    "word_count.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "linesWithSpark = lines.filter(lambda x: \"spark\" in x.lower())\n",
    "print linesWithSpark.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"createdAt\":\"Nov 4, 2014 4:56:59 PM\",\"id\":529799371026485248,\"text\":\"Adventures With Coffee, Code, and Writing.\",\"source\":\"\\u003ca href\\u003d\\\"http://twitter.com\\\" rel\\u003d\\\"nofollow\\\"\\u003eTwitter Web Client\\u003c/a\\u003e\",\"isTruncated\":false,\"inReplyToStatusId\":-1,\"inReplyToUserId\":-1,\"isFavorited\":false,\"retweetCount\":0,\"isPossiblySensitive\":false,\"contributorsIDs\":[],\"userMentionEntities\":[],\"urlEntities\":[],\"hashtagEntities\":[],\"mediaEntities\":[],\"currentUserRetweetId\":-1,\"user\":{\"id\":15594928,\"name\":\"Holden Karau\",\"screenName\":\"holdenkarau\",\"location\":\"\",\"description\":\"\",\"descriptionURLEntities\":[],\"isContributorsEnabled\":false,\"profileImageUrl\":\"http://pbs.twimg.com/profile_images/3005696115/2036374bbadbed85249cdd50aac6e170_normal.jpeg\",\"profileImageUrlHttps\":\"https://pbs.twimg.com/profile_images/3005696115/2036374bbadbed85249cdd50aac6e170_normal.jpeg\",\"isProtected\":false,\"followersCount\":1231,\"profileBackgroundColor\":\"C0DEED\",\"profileTextColor\":\"333333\",\"profileLinkColor\":\"0084B4\",\"profileSidebarFillColor\":\"DDEEF6\",\"profileSidebarBorderColor\":\"FFFFFF\",\"profileUseBackgroundImage\":true,\"showAllInlineMedia\":false,\"friendsCount\":600,\"createdAt\":\"Aug 5, 2011 9:42:44 AM\",\"favouritesCount\":1095,\"utcOffset\":-3,\"profileBackgroundImageUrl\":\"\",\"profileBackgroundImageUrlHttps\":\"\",\"profileBannerImageUrl\":\"\",\"profileBackgroundTiled\":true,\"lang\":\"en\",\"statusesCount\":6234,\"isGeoEnabled\":true,\"isVerified\":false,\"translator\":false,\"listedCount\":0,\"isFollowRequestSent\":false}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import urllib2\n",
    "data = urllib2.urlopen('https://raw.githubusercontent.com/databricks/learning-spark/master/files/testweet.json').read()\n",
    "print data\n",
    "rdd = sc.parallelize([data])\n",
    "path = \"wasb://asadk-sparkml@asdfasdf782x8m60.blob.core.windows.net/magic2/\"\n",
    "rdd.saveAsTextFile(\"wasb://asadk-sparkml@asdfasdf782x8m60.blob.core.windows.net/magic2/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _corrupt_record: string (nullable = true)\n",
      " |-- contributorsIDs: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- createdAt: string (nullable = true)\n",
      " |-- currentUserRetweetId: long (nullable = true)\n",
      " |-- hashtagEntities: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- inReplyToStatusId: long (nullable = true)\n",
      " |-- inReplyToUserId: long (nullable = true)\n",
      " |-- isFavorited: boolean (nullable = true)\n",
      " |-- isPossiblySensitive: boolean (nullable = true)\n",
      " |-- isTruncated: boolean (nullable = true)\n",
      " |-- mediaEntities: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- retweetCount: long (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- urlEntities: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- user: struct (nullable = true)\n",
      " |    |-- createdAt: string (nullable = true)\n",
      " |    |-- description: string (nullable = true)\n",
      " |    |-- descriptionURLEntities: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- favouritesCount: long (nullable = true)\n",
      " |    |-- followersCount: long (nullable = true)\n",
      " |    |-- friendsCount: long (nullable = true)\n",
      " |    |-- id: long (nullable = true)\n",
      " |    |-- isContributorsEnabled: boolean (nullable = true)\n",
      " |    |-- isFollowRequestSent: boolean (nullable = true)\n",
      " |    |-- isGeoEnabled: boolean (nullable = true)\n",
      " |    |-- isProtected: boolean (nullable = true)\n",
      " |    |-- isVerified: boolean (nullable = true)\n",
      " |    |-- lang: string (nullable = true)\n",
      " |    |-- listedCount: long (nullable = true)\n",
      " |    |-- location: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- profileBackgroundColor: string (nullable = true)\n",
      " |    |-- profileBackgroundImageUrl: string (nullable = true)\n",
      " |    |-- profileBackgroundImageUrlHttps: string (nullable = true)\n",
      " |    |-- profileBackgroundTiled: boolean (nullable = true)\n",
      " |    |-- profileBannerImageUrl: string (nullable = true)\n",
      " |    |-- profileImageUrl: string (nullable = true)\n",
      " |    |-- profileImageUrlHttps: string (nullable = true)\n",
      " |    |-- profileLinkColor: string (nullable = true)\n",
      " |    |-- profileSidebarBorderColor: string (nullable = true)\n",
      " |    |-- profileSidebarFillColor: string (nullable = true)\n",
      " |    |-- profileTextColor: string (nullable = true)\n",
      " |    |-- profileUseBackgroundImage: boolean (nullable = true)\n",
      " |    |-- screenName: string (nullable = true)\n",
      " |    |-- showAllInlineMedia: boolean (nullable = true)\n",
      " |    |-- statusesCount: long (nullable = true)\n",
      " |    |-- translator: boolean (nullable = true)\n",
      " |    |-- utcOffset: long (nullable = true)\n",
      " |-- userMentionEntities: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext.jsonFile(path)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error = 0.363354037267\n"
     ]
    }
   ],
   "source": [
    "# Example from Spark Docs @ http://spark.apache.org/docs/1.3.1/mllib-linear-methods.html\n",
    "from pyspark.mllib.classification import LogisticRegressionWithSGD\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from numpy import array\n",
    "\n",
    "# Load and parse the data\n",
    "def parsePoint(line):\n",
    "    values = [float(x) for x in line.split(' ')]\n",
    "    return LabeledPoint(values[0], values[1:])\n",
    "\n",
    "data = sc.textFile(\"file:///\"+os.environ['SPARK_HOME']+\"/data/mllib/sample_svm_data.txt\")\n",
    "parsedData = data.map(parsePoint)\n",
    "\n",
    "# Build the model\n",
    "model = LogisticRegressionWithSGD.train(parsedData)\n",
    "\n",
    "# Evaluating the model on training data\n",
    "labelsAndPreds = parsedData.map(lambda p: (p.label, model.predict(p.features)))\n",
    "trainErr = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(parsedData.count())\n",
    "print(\"Training Error = \" + str(trainErr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
